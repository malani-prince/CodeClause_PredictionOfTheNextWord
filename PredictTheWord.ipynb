{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a029c2-7402-467f-8807-3049f327946c",
   "metadata": {},
   "source": [
    "<h1>Project-4</h1> \n",
    "<h2><u>Aim : Prediction Of The Next Word</u></h2>\n",
    "<h3 style=\"color:DodgerBlue;\"><u> D A T A S C I E N C E &nbsp I N T E R N S H I P</u></h3> \n",
    "<h4>Deep Learning model use for the Prediction onf the data <u> Tensorflow .</u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b301b60-9ec3-4286-a037-27b288006272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding , LSTM , Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9563451-c8bf-488f-9c76-4237f8f4fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('Story.txt' , 'r' , encoding= \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0348eb-aeb1-45e3-8272-6922ec3a9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for i in f1:\n",
    "    lines.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01654b00-bc01-41b8-b21e-94acf51d856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Golden rules of medical evidence, by Stanley B. Atkinson  This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or reuse it under the terms of the Project Gutenberg License included wi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_string = \"\"\n",
    "for i in lines:\n",
    "      whole_string = \" \".join(lines)\n",
    "        \n",
    "final_string = whole_string.replace(\"\\n\" , '').replace('*' , \"\").replace('=', '').replace('\"' , ' ').replace('_' , '').replace(\"-\", \"\").replace('\"' , \"\")\n",
    "final_string[:346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc88436-4c5c-4352-b561-1b44cf0f709b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Golden rules of medical evidence, by'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final_string.split()\n",
    "data  = ' '.join(data)\n",
    "data[:67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8637430-3fe1-4d52-b873-69342100e58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60275"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6deb6b3-714c-4169-aae2-d773162ffc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9993"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts([data])\n",
    "\n",
    "# save tokenizer for the predict function\n",
    "pickle.dump(tokenizer_obj , open('token.pkl' , 'wb'))\n",
    "\n",
    "sequence_data = tokenizer_obj.texts_to_sequences([data])[0]\n",
    "len(sequence_data)    # Repeted Word Deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ff5b2d-4f8d-4281-8fd8-200c9f155305",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_obj.word_index )\n",
    "vocab_size +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d265d51-a803-44ad-86d1-c7e1b97a0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_data = []\n",
    "\n",
    "for i in range(3 , len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    combination_data.append(words)\n",
    "    \n",
    "combination_array = np.array(combination_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f50e6b8-dba3-4507-9d30-430ec023e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   12,   36,  106],\n",
       "       [  12,   36,  106,    2],\n",
       "       [  36,  106,    2,   56],\n",
       "       ...,\n",
       "       [2340,    3, 2341,  140],\n",
       "       [   3, 2341,  140,  591],\n",
       "       [2341,  140,  591,  214]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combination_array)\n",
    "combination_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2978a54-e4ab-4993-8637-dd84d618f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [] \n",
    "y = []\n",
    "\n",
    "for i in combination_array:\n",
    "    x.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "\n",
    "X_array = np.array(x)\n",
    "Y_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a9f0d5-31ed-4958-be3d-96785f4a3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data :  [[  1  12  36]\n",
      " [ 12  36 106]\n",
      " [ 36 106   2]\n",
      " [106   2  56]\n",
      " [  2  56  45]\n",
      " [ 56  45   2]\n",
      " [ 45   2  17]\n",
      " [  2  17  20]\n",
      " [ 17  20  11]\n",
      " [ 20  11 314]]\n",
      "Response :  [106   2  56  45   2  17  20  11 314  70]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9990, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data : \",X_array[:10] )\n",
    "print(\"Response : \",Y_array[:10])\n",
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe93141-2a15-4979-b45b-af98bdcabd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion into byte matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d297490d-0c38-4934-8b92-0c235fc405d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9990, 2342)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = to_categorical(Y_array ,  )\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c4c36b-a287-4864-ae25-71e184295a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1780ad0b-f268-41e1-9ed0-025185f22f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size , 10 , input_length=3))\n",
    "model.add(LSTM(1000 , return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000 , activation=\"relu\"))\n",
    "model.add(Dense(vocab_size , activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20754d1-015b-42a0-8215-a8c86820040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             23420     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2342)              2344342   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,416,762\n",
      "Trainable params: 15,416,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afeea0c4-823a-4ec4-b827-1cf749a39b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model visual look out of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898f0bea-5e27-4cf6-9ca8-1da122c5e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b03d8b7a-dfd8-4d33-9eab-27b41351f684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 7.1001\n",
      "Epoch 1: loss improved from inf to 7.10007, saving model to next_words.h5\n",
      "157/157 [==============================] - 104s 627ms/step - loss: 7.1001\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.3949\n",
      "Epoch 2: loss improved from 7.10007 to 6.39494, saving model to next_words.h5\n",
      "157/157 [==============================] - 93s 594ms/step - loss: 6.3949\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.3190\n",
      "Epoch 3: loss improved from 6.39494 to 6.31905, saving model to next_words.h5\n",
      "157/157 [==============================] - 94s 595ms/step - loss: 6.3190\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.2309\n",
      "Epoch 4: loss improved from 6.31905 to 6.23087, saving model to next_words.h5\n",
      "157/157 [==============================] - 95s 603ms/step - loss: 6.2309\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.1549\n",
      "Epoch 5: loss improved from 6.23087 to 6.15489, saving model to next_words.h5\n",
      "157/157 [==============================] - 93s 589ms/step - loss: 6.1549\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.0811\n",
      "Epoch 6: loss improved from 6.15489 to 6.08112, saving model to next_words.h5\n",
      "157/157 [==============================] - 95s 607ms/step - loss: 6.0811\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 6.0124\n",
      "Epoch 7: loss improved from 6.08112 to 6.01239, saving model to next_words.h5\n",
      "157/157 [==============================] - 94s 601ms/step - loss: 6.0124\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.9344\n",
      "Epoch 8: loss improved from 6.01239 to 5.93439, saving model to next_words.h5\n",
      "157/157 [==============================] - 93s 590ms/step - loss: 5.9344\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.8422\n",
      "Epoch 9: loss improved from 5.93439 to 5.84215, saving model to next_words.h5\n",
      "157/157 [==============================] - 97s 617ms/step - loss: 5.8422\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - ETA: 0s - loss: 5.9531\n",
      "Epoch 10: loss did not improve from 5.84215\n",
      "157/157 [==============================] - 91s 579ms/step - loss: 5.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14301fc42e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\" , monitor= 'loss' , verbose= 1  , save_best_only = True)\n",
    "model.compile(loss=\"categorical_crossentropy\" , optimizer=Adam(learning_rate=0.01))\n",
    "model.fit(X_array , matrix , epochs=10, batch_size = 64 ,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "066c9113-1d5f-42a9-b831-2ef51d3232da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl' , 'rb'))\n",
    "\n",
    "def Prediction_of_the_next_word(model , tokenizer , text):\n",
    "    seq = tokenizer_obj.texts_to_sequences([text])\n",
    "    seq = np.array(seq)\n",
    "    pred = np.argmax(model.predict(seq))\n",
    "    predicted_word =  \"\"\n",
    "    \n",
    "    for key, value in tokenizer.word_index.items():\n",
    "        if value == pred:\n",
    "            predicted_word = key\n",
    "            break\n",
    "        \n",
    "    print(predicted_word)\n",
    "    return predicted_word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c8d1ac0-cb3d-40b9-b468-dd9b0e113e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter String :   Neuromuscular action and sudden death,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'sudden', 'death,']\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "the\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = input(\"Enter String : \")\n",
    "\n",
    "text = text.split(\" \")\n",
    "text = text[-3:]\n",
    "print(text)\n",
    "Prediction_of_the_next_word(model , tokenizer, text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bdd1b-1bdd-41e4-9642-bc4512514d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a68275-f60b-4cec-abd9-57fedfa8441b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24474b-d600-4bdb-b664-31751884f089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d6481-e3da-44e7-a242-b2e64c59a35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
